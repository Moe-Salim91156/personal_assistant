0) Quick orientation (what we’re building, in one line)

A single-process, event-driven HTTP/1.0 server written in C++98 that uses non-blocking sockets + one poll/select/epoll/kqueue loop, parses HTTP requests incrementally, serves static files, handles POST uploads and DELETE, runs CGI programs, enforces configuration rules and limits, and never blocks or crashes. The subject requires using a configuration file, default error pages, multiple listen ports, and at least GET/POST/DELETE. 

en.subject (1)

1) OS / Networking primitives — the foundation
Concept: TCP sockets

A socket is an OS endpoint for networking. For a server you socket(), bind() to an address:port, listen(), then accept() new connection sockets.

Each accepted client is a file descriptor (fd) you read()/write() from.

Why it matters for Webserv

Every HTTP request arrives as bytes on a client socket. Correct handling of sockets (listen, accept, non-blocking mode) is the starting point for the whole system.

Concept: Non-blocking I/O

O_NONBLOCK means syscalls (read/write) return immediately rather than block waiting for data or buffer space.

When non-blocking, read() might return -1/EAGAIN if nothing is available; write() might write fewer bytes than requested. BUT: the project forbids changing server behavior based on errno after read/write, so you must rely on poll-like readiness notifications instead of polling errno. 

en.subject (1)

Why for Webserv

Prevent a slow client or disk operation from stalling the entire server. The subject forces non-blocking for correctness and grading.

Concept: Multiplexing (poll/select/epoll/kqueue)

These system calls let you monitor many fds for readiness (readable, writable, errors) and react only when OS says ready.

The project requires exactly one poll (or equivalent) for all I/O between server and clients (listen included). That means one centralized event loop. 

en.subject (1)

Why

Single event loop == single-threaded, deterministic, easier to reason about resource usage (file descriptors, memory). It’s what graders expect.

2) HTTP/1.0 — what it is and how it changes design
What HTTP/1.0 is (the minimal facts)

Text protocol over TCP. Request format:

METHOD SP request-target SP HTTP/1.0 CRLF
header-name: value CRLF
...
CRLF
[optional body]


Response format:

HTTP/1.0 SP status-code SP reason-phrase CRLF
header: value CRLF
...
CRLF
[body]


Important difference to HTTP/1.1:

HTTP/1.0 typically uses connection-close to delimit messages (if there is no Content-Length, the server/client close the connection to indicate end-of-body).

Chunked transfer encoding is an HTTP/1.1 feature, not in HTTP/1.0. However: the subject explicitly mentions that if you receive chunked requests you must un-chunk before passing to CGI — so your server needs to be able to decode chunked bodies if they occur. 

en.subject (1)

Methods you must implement

GET — return a resource (a file or directory index)

POST — accept data (forms, multipart uploads, or body for CGI)

DELETE — remove resources (when allowed by location config)

Response headers you need to care about (minimal)

Content-Length — tells recipient how many body bytes follow (critical for correct clients).

Content-Type — MIME type of the body.

Connection — in HTTP/1.0, default is close unless Connection: keep-alive used.

Date, Server — helpful but not required by the project.

Why HTTP/1.0 shapes design

Because body-delimiting often relies on connection closure, you must treat missing Content-Length carefully (especially for POST). For CGI interaction and uploads you must either require content-length or read until close. The subject explicitly notes CGI expects EOF as end if Content-Length not returned. 

en.subject (1)

3) Incremental parsing & connection state machine (core logic)
Why incremental parsing?

TCP is a byte stream — a single read() may return 1 byte, all headers, headers+part of body, or multiple pipelined requests. You cannot assume whole HTTP messages arrive in one syscall.

Per-connection state machine (the simplest correct shape)

READING_HEADERS — append bytes until you detect header terminator (\r\n\r\n). Then parse request-line and headers.

HEADERS_PARSED — decide presence of body:

Content-Length → expect N bytes → READING_BODY

Transfer-Encoding: chunked → READING_CHUNKED_BODY (even though chunked is 1.1, implement decoding as subject may expect it for CGI).

No body → PROCESSING

READING_BODY / READING_CHUNKED_BODY — read and accumulate or stream to temporary file until complete.

PROCESSING — route request (static/CGI/upload/delete), produce a Response or spawn CGI.

SENDING — send response headers then body, using non-blocking writes, handling partial writes.

DONE — either close connection (HTTP/1.0 default) or loop back to READING_HEADERS if keep-alive is in effect and read buffer contains leftover bytes (pipelining).

Implementation notes

Keep per-connection read_buffer (byte vector/string), write_queue (deque of buffers), state, last_activity (timeout), and parsing metadata (expected content-length, chunk decode state, path, headers).

Always call read() only when poll indicates fd is readable; same for write() and POLLOUT. The subject forbids reads/writes outside poll usage. 

en.subject (1)

4) How the event loop ties everything together
Single event loop responsibilities

Accept new connections (listen sockets are polled for readable).

Poll all client sockets for readability/writability/errors.

Poll other fds you use (non-blocking CGI pipes).

Drive per-connection state machines (call handle_read/handle_write etc. only when poll reports readiness).

Enforce timeouts and limits (close idle or misbehaving connections).

A minimal event loop sketch (pseudocode)
setup_listeners(); // bind/listen, O_NONBLOCK
fds = [listeners fds]; // registered in poll
while (true) {
  poll(fds, timeout);
  for each fd with event:
    if fd is listener && readable: accept loop -> add clients
    else if fd is client:
      if POLLIN: connection.read_into_buffer()
      if POLLOUT: connection.flush_write_queue()
      if ERR/HUP: close_connection()
  reap_children();
  cleanup_timeouts();
}


Important: the subject requires one poll/select/epoll/kqueue for all I/O between clients and server — you can use any of them but centralize. 

en.subject (1)

5) Static file serving — mapping URL → filesystem safely
Steps

Route decides this is a static handling (via config location).

Build filesystem path: fs_path = root + requested_path.

Canonicalize (e.g., realpath() or manual normalization) and verify fs_path is within root to prevent ../ traversal.

stat() the file:

If directory → check for index file or autoindex config.

If file, open() and read/send.

Send headers (Content-Length from stat()), then stream file contents in chunks using non-blocking read + write.

Key low-level points

Use a safe read buffer size (e.g., 16KB) and send portions to avoid blocking the server for long disk reads.

Use sendfile() if allowed and beneficial — but subject doesn’t require it; simple read() → write() is fine.

Why canonicalization matters: prevents path traversal and leaking files outside root.

6) CGI — process model, pipes, and environment
What CGI does

Runs an external program (php-cgi, python, your script) that reads the HTTP request (via environment variables and stdin), produces headers + body on stdout; server forwards that to the client.

Steps & low-level mapping

Server decides location requires CGI (extension match in config). 

en.subject (1)

Create pipes: pipe_in (server → CGI stdin), pipe_out (CGI stdout → server).

fork():

child: dup2(pipe_in_read, STDIN_FILENO), dup2(pipe_out_write, STDOUT_FILENO), chdir() to script dir, execve(cgi_bin, args, envp).

parent: close child ends, keep pipe_in_write and pipe_out_read.

Parent streams request body into pipe_in_write (non-blocking, using poll for POLLOUT), then closes pipe_in_write to signal EOF.

Parent reads CGI stdout (non-blocking), parse CGI headers (they look like HTTP headers) until empty line, then treat remaining content as CGI body and send to client.

Reap child via waitpid() or handle SIGCHLD. The subject forbids using fork() except for CGI. 

en.subject (1)

Important details & why they matter

Non-blocking pipes + poll: do not block waiting for CGI stdout or blocking on writing CGI stdin — integrate CGI pipes into the same event loop.

Environment variables: set REQUEST_METHOD, QUERY_STRING, CONTENT_LENGTH, CONTENT_TYPE, SCRIPT_NAME, PATH_INFO, SERVER_NAME, SERVER_PORT, and HTTP_* for headers; CGI reads information from env. The subject emphasizes env vars. 

en.subject (1)

EOF semantics: if CGI does not set Content-Length, EOF marks end of CGI output — server must support streaming until child closes stdout. The subject explicitly states this. 

en.subject (1)

7) Multipart/form-data uploads (streaming parser)
Why streaming?

Uploaded files can be large — don’t store them fully in memory. Stream parts to disk as you detect content.

Multipart structure (high level)

Content-Type: multipart/form-data; boundary=----XXX

Body is sequence: --boundary CRLF part-headers CRLF CRLF part-data CRLF --boundary (repeat) --boundary-- (end)

Parsing strategy

Keep a sliding read_buffer. Search for boundary sequences (they may be split across reads — so keep an overlap buffer).

On part header completion: parse Content-Disposition (gives name and filename) and Content-Type.

If filename present → open a temp file and stream the part data until boundary is found.

After part finished → close file, record metadata (size, saved path).

Enforce client_max_body_size from config and per-request limits; abort with 413 if exceeded.

Low-level trick

Use an efficient boundary search (e.g., memmem, or KMP) on the buffered data while preserving the last boundary_length-1 bytes between reads to catch cross-boundary splits.

Why this is graded: the subject requires file uploads and storage location configuration. 

en.subject (1)

8) Chunked transfer decoding (when you encounter it)
When you’ll see it

Chunked is an HTTP/1.1 feature; however the subject instructs you must un-chunk before passing to CGI if you ever get chunked requests (some clients or tests may do this). 

en.subject (1)

Chunk format (brief)
<hex-size>\r\n
<data (size bytes)>\r\n
[repeat]
0\r\n
[optional trailers]\r\n
\r\n

How to implement

Parse chunk-size lines (hex). Read exactly that many bytes of chunk-data, then expect \r\n. Repeat until size==0. Then process optional trailers (headers).

Decode streaming: keep a state for READ_SIZE_LINE, READ_CHUNK_DATA, READ_CRLF_AFTER_CHUNK, etc., and only change state when enough bytes read.

Present decoded bytes as the real body for CGI or for storage.

Pitfall

Chunk extensions exist (e.g., 4;ext=value) — you can ignore extensions but must parse the hex size.

9) Security and robustness (must-haves)
Path traversal protection

Always canonicalize requested path (e.g., realpath() or manual normalization). Deny requests that resolve outside the configured root.

Resource limits

client_max_body_size — enforced per config. If exceeded return 413.

Max open fds — handle EMFILE gracefully (close oldest idle connections).

Max CGI processes — avoid forking unlimited children.

Deny dangerous filenames

For uploads: strip directory separators from filename, remove .., generate unique names (timestamp + random or UUID), set correct file permissions.

Timeouts

Header read timeout, body read timeout, CGI exec timeout, idle keep-alive timeout — close or abort when exceeded.

Error responses

Return meaningful HTTP status codes and default HTML error pages (subject requires default error pages if none provided). 

en.subject (1)

10) Configuration & routing (NGINX-like, minimal grammar)
Config features required by subject

Listen addresses / ports (multiple).

Per-server root, error_page mapping, client_max_body_size.

location blocks with rules:

Allowed methods list

Redirects

Root for that path

Directory listing toggle

Default index file

Upload directory

CGI extension mapping (e.g., .php) so matching requests run CGI. 

en.subject (1)

Practical parser approach

Simple recursive-descent token parser that supports: server { ... }, location /path { ... }, and simple directives ending with ;.

Validate values (paths exist, numbers positive).

Why config matters

Behavior differs per route; routings control security and features (e.g., only certain locations allow DELETE or uploads).

11) The allowed system calls — why they’re present (map to features)

Below I list the calls the subject lists and explain their purpose in the server:

socket, bind, listen, accept — create and accept network connections (foundation).

setsockopt — set SO_REUSEADDR, socket options (rebind after restart).

getaddrinfo, freeaddrinfo, htons/ntohs/htonl/ntohl, getprotobyname — address resolution and network byte-order helpers for robust cross-platform network binds.

fcntl — set O_NONBLOCK and FD_CLOEXEC on fds (non-blocking + safe exec semantics); MacOS allowed only some flags. 

en.subject (1)

select / poll / epoll / kqueue — event multiplexing (one required).

read, write, send, recv — I/O on sockets and pipes — use them only when poll signals readiness.

open, stat, access, opendir, readdir, closedir, close — filesystem operations for serving files, checking existence, listing directories.

execve, fork, pipe, dup, dup2, waitpid, kill, signal — process and IPC primitives for CGI:

pipe() to create stdin/stdout pipes,

fork() to spawn CGI child,

dup2() to attach pipes to child's stdin/stdout,

execve() to run the CGI program,

waitpid()/signal to reap child processes.

Subject forbids fork() for anything but CGI. 

en.subject (1)

send/recv vs read/write — either is fine; send/recv have flags but read/write are simpler.

getpeername / getsockname — (not explicitly listed but common) — to obtain remote/local addresses if needed.

stat/open → to get file size and then stream.

Everything above is allowed by the subject and maps directly to features (networking, non-blocking IO, CGI, filesystem). The subject lists these exact functions, so each is there for a precise reason. 

en.subject (1)

12) Module / code organization (how to design the code)

Suggested modules and data structures:

Config parser

Config, ServerBlock, LocationBlock classes/structs.

Unit tests for parser with invalid and valid configs.

Network / Poll manager

Listener objects (fd, bound addr).

Poller wrapper around poll() / epoll / select.

Connection object

fd, read_buffer, write_queue, state, request and response objects, last_activity, cgi_context if any, multipart_context if any.

HTTP Parser

Robust incremental parser: header line parsing, request-line parse, header normalization (lowercase keys).

Router / RequestHandler

Given a parsed Request + server config → decide static/CGI/upload/redirect/delete, enforce allowed methods and max body size.

StaticFileHandler

Path resolution, stat, open, streaming reads.

CGIHandler

Manage pipes, fork/exec, env setup, streaming stdin/out via poll.

UploadParser

Multipart streaming parser, file writing, sanitization.

ResponseBuilder

Build status-line + headers, manage Content-Length and Connection.

Logger & Tests

request logs, errors, debug flags.

Why modular?

Cleaner tests, easier to reason about correctness, and easier to debug during evaluation.

13) Testing, debugging, and evaluation checklist
Manual tests you must run

curl -v GET static file index.html.

GET directory → index file served or 403/autoindex as per config.

POST form (simple): curl -d 'a=b' http://...

POST multipart upload: curl -F "file=@my.png" http://... → file saved in upload dir.

DELETE a file: curl -X DELETE http://.../upload/thatfile

CGI test: a test.php or test.py script that echoes env vars and POST body; ensure you see CGI output.

Malformed requests (bad header lines) → 400 Bad Request.

Large upload > client_max_body_size → 413 Payload Too Large.

Multiple listen ports → serve different content on different ports.

Use telnet for very low-level tests: send partial headers, close mid-body, etc.

Stress tests

Write a script to open many concurrent connections and issue requests (Python asyncio or a simple threading script). Ensure server remains responsive.

Debugging tips

Log per-request unique id and state transitions.

Print read_buffer/write_queue snapshots in debug mode (not in release).

Compare behavior to NGINX for ambiguous cases (subject suggests using it for comparison). 

en.subject (1)

14) Readiness checklist — what you must understand and have working before tackling the full project

Master these before full implementation:

C++98 basics and Unix build (Makefile rules) — compile with -std=c++98 -Wall -Wextra -Werror. 

en.subject (1)

Unix sockets and accept() loop — create a simple TCP server that accepts and echoes bytes.

Non-blocking mode + poll() — small demo: echo server with poll-driven reads/writes.

Incremental HTTP parsing — implement a parser that handles headers arriving in chunks and can parse a simple GET request.

Static file serving — map URL to root path, canonicalize, stat(), open() and stream file content.

Implement config parser — parse basic server and location directives.

Implement POST body reading w/ Content-Length — buffer to memory or stream to temp file if large.

Multipart parsing (upload) — streaming write to disk for file parts.

CGI basics — fork/exec sample: server pipes body to child stdin and reads back child's stdout. Handle env vars. 

en.subject (1)

Error handling & status codes — return 400/404/403/413/500/501/405 correctly and have default error pages. 

en.subject (1)

Robustness — handle client disconnect, timeouts, and resource limits; always close fds properly and waitpid() children.

When all items 1–11 are implemented and tested (unit + manual + stress), you’re ready for full project polish and the final submission.

15) Concrete milestone plan (ordered, with acceptance criteria — no time estimates)

Implement in small, testable steps. For each milestone I give the goal and acceptance criteria:

Milestone A — Foundation

Implement config parser (parse at least listen, root, error_page, client_max_body_size, and a simple location with root and methods).

Acceptance: ./webserv conf starts without runtime error; sample config loaded and printed via --show-config dev flag.

Milestone B — Non-blocking event loop

Build poll-based event loop, accept connections, support one fd poll for listeners and clients.

Acceptance: echo server demo using same loop; handles multiple clients concurrently.

Milestone C — HTTP parser + static GET

Add incremental parser, state machine, static file serving with path canonicalization.

Acceptance: curl http://localhost:port/index.html returns correct bytes and Content-Length; ../ attack tests blocked.

Milestone D — POST body + file streaming and DELETE

Implement Content-Length-based POST reading with streaming to temp file when big; implement DELETE to remove allowed files.

Acceptance: curl -X POST --data-binary @largefile saved to upload dir; curl -X DELETE removes file and returns 204.

Milestone E — Multipart upload

Implement multipart/form-data streaming parser, save files to configured upload_dir.

Acceptance: curl -F "file=@pic.png" http://.../upload stores file, sanitized filename, size within limit.

Milestone F — CGI

Implement CGI runner with environment, non-blocking pipes, and streaming stdin/out. Ensure child reaping.

Acceptance: CGI script echoes env and body; curl to .php or .py returns expected output. If CGI prints no Content-Length, server streams until EOF.

Milestone G — Robustness + timeouts + tests

Add timeouts, limit enforcement, error pages, logging, and stress tests.

Acceptance: server survives stress test and returns correct error codes for malformed input.

Milestone H — Polish + packaging

Makefile, sample configs, default error pages, documentation for evaluator.

Acceptance: Pass your own test suite and be able to demo all required features cleanly.

(You can implement milestones incrementally — keep early commits small and test each feature thoroughly.)

16) Final “Why things operate this way” summary (the core design rationale)

One poll loop + non-blocking: required by subject and best for simple concurrency without threads. It gives predictable control flow and avoids race conditions and complex locking.

Incremental parsing & per-connection state: TCP fragmentation requires buffering and a state machine per connection. Without this, partial reads break parsing.

Stream uploads to disk: memory is finite. Streaming prevents OOM for large bodies.

CGI via fork + pipes: CGI needs a separate process with stdio pipes; fork/exec is the simplest portable mechanism allowed and the subject explicitly permits it only for CGI. Integrate CGI fds into the same event loop so the server never blocks waiting for a child.

Canonicalize file paths: security — preventing traversal attacks is mandatory.

Strict I/O behavior (only read/write when poll says ready, no errno-based behavior): avoids incorrect behavior on edge races and makes server portable across OSes. The subject mandates this rule; follow it or fail. 

en.subject (1)

17) Quick pointer to the subject’s hard constraints (so you don’t miss them while coding)

Use one poll/select/epoll/kqueue for all I/O (listen included). 

en.subject (1)

Never perform read/write ops without going through poll (or equivalent). 

en.subject (1)

Do not change server behavior by checking errno after read/write. 

en.subject (1)

Must support GET/POST/DELETE, uploads, CGI, default error pages, multiple listen ports, config file, non-blocking, and survive stress tests.

18) Suggested next move (what you should do right now)

Pick one small concrete task to implement and test so you get momentum:

Option 1 (recommended): Implement a minimal poll-based skeleton that accepts connections and echoes back “HTTP/1.0 200 OK\r\nContent-Length: 2\r\n\r\nOK” to any connection. This proves networking, polling, non-blocking, and write queuing all work.

Option 2: Implement the config parser and a small CLI ./webserv conf.conf --print-config so the config structure is correct before wiring the network.
this exact respone i want to be able to donwoload it as pdf , md , and txt file 
with syntax higilhgint and formatting 

